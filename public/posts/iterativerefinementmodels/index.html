<!DOCTYPE html>
<html lang="en-us">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Iterative Refinement in LLMs | An eclectic mix of technical content!</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Q to Gemini: Suppose during inference we are at token 65, but it turns out token 23 now has a low probability. There is now a much better token that should be chosen for token 23. Does it make sense to update toekn 23 and throw away all the tokens after token 23 and restart the inference? Do any models do this? How effective would this
Gemini A: Yes, this is a fascinating idea!">
    <meta name="generator" content="Hugo 0.123.7">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    

    
      

    

    

    
      <link rel="canonical" href="http://localhost:1313/posts/iterativerefinementmodels/">
    

    <meta property="og:title" content="Iterative Refinement in LLMs" />
<meta property="og:description" content="Q to Gemini: Suppose during inference we are at token 65, but it turns out token 23 now has a low probability. There is now a much better token that should be chosen for token 23. Does it make sense to update toekn 23 and throw away all the tokens after token 23 and restart the inference? Do any models do this? How effective would this
Gemini A: Yes, this is a fascinating idea!" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/posts/iterativerefinementmodels/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-03-07T08:50:13-05:00" />
<meta property="article:modified_time" content="2024-03-07T08:50:13-05:00" />

<meta itemprop="name" content="Iterative Refinement in LLMs">
<meta itemprop="description" content="Q to Gemini: Suppose during inference we are at token 65, but it turns out token 23 now has a low probability. There is now a much better token that should be chosen for token 23. Does it make sense to update toekn 23 and throw away all the tokens after token 23 and restart the inference? Do any models do this? How effective would this
Gemini A: Yes, this is a fascinating idea!"><meta itemprop="datePublished" content="2024-03-07T08:50:13-05:00" />
<meta itemprop="dateModified" content="2024-03-07T08:50:13-05:00" />
<meta itemprop="wordCount" content="718">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Iterative Refinement in LLMs"/>
<meta name="twitter:description" content="Q to Gemini: Suppose during inference we are at token 65, but it turns out token 23 now has a low probability. There is now a much better token that should be chosen for token 23. Does it make sense to update toekn 23 and throw away all the tokens after token 23 and restart the inference? Do any models do this? How effective would this
Gemini A: Yes, this is a fascinating idea!"/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        An eclectic mix of technical content!
      
    </a>
    <div class="flex-l items-center">
      

      
      
<div class="ananke-socials">
  
</div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked ttu">
          
        Posts
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
  </div>


      <h1 class="f1 athelas mt3 mb1">Iterative Refinement in LLMs</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2024-03-07T08:50:13-05:00">March 7, 2024</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>Q to Gemini:
Suppose during inference we are at token 65, but it turns out token 23 now has a low probability. There is now a much better token that should be chosen for token 23. Does it make sense to update toekn 23 and throw away all the tokens after token 23 and restart the inference? Do any models do this? How effective would this</p>
<p>Gemini A:
Yes, this is a fascinating idea! While it&rsquo;s not a common mainstream method in LLMs, there&rsquo;s definitely merit and ongoing research exploring similar approaches. Here&rsquo;s a breakdown:</p>
<p><strong>The Concept</strong></p>
<p>Your intuition is correct – if we realize a past token choice was suboptimal, revising it could lead to a globally better output. This is analogous to how humans sometimes rewrite earlier parts of a sentence as they gain a clearer understanding of their message.</p>
<p><strong>Models That Do Something Similar</strong></p>
<ul>
<li><strong>Iterative Refinement Models:</strong>  Some generative models employ iterative refinement. They don&rsquo;t directly &lsquo;go back&rsquo; but might generate multiple drafts of an output and then select or combine the best parts. This indirectly addresses the past choice issue.</li>
<li><strong>Search-based Techniques:</strong>  Methods like beam search keep track of multiple possible sequences. A low-probability token early on doesn&rsquo;t mean its corresponding sequence is discarded immediately.  If subsequent predictions turn out incredibly strong, that sequence might still be the winner.</li>
<li><strong>Models with &ldquo;Editable&rdquo; Memory:</strong>  There&rsquo;s emerging research on LLMs with memory mechanisms that are more explicitly editable. This could pave the way for directly revising earlier tokens if needed.</li>
</ul>
<p><strong>Effectiveness in Practice</strong></p>
<ul>
<li><strong>Potential Improvement:</strong>  There&rsquo;s strong potential for quality improvement. Human language is highly interconnected – earlier choices significantly constrain what works well later in the text.</li>
<li><strong>Computational Cost:</strong>   This is the major issue. Revising a token would likely necessitate re-running inference for all subsequent tokens, which quickly becomes expensive, especially in long sequences.</li>
<li><strong>Determining When to Revise:</strong>  It&rsquo;s tricky to decide <em>when</em> a past token is bad enough to warrant the computational overhead of a revision.</li>
</ul>
<p><strong>Research Directions</strong></p>
<ul>
<li><strong>Efficient Revision Mechanisms:</strong>  Research could focus on ways to efficiently update the internal state of the model after token revision without a full recalculation.</li>
<li><strong>Selective Revision:</strong> Developing heuristics to identify the most crucial tokens likely to benefit from revision, minimizing the computational cost.</li>
<li><strong>Hybrid approaches:</strong>  Combining this idea with iterative refinement or search-based techniques might yield a more practical balance.</li>
</ul>
<p><strong>Let me know if you&rsquo;d like links to specific research papers. It&rsquo;s a less mainstream area, but a very interesting one for improving LLM generation!</strong></p>
<p>Q: Does the model calculate or retain prababilities for words already generated? Are these used in any way during inference or training?</p>
<p>Gemini Answer:
Absolutely! Here&rsquo;s a look at some relevant research directions on revising tokens or improving LLM generation through techniques that indirectly address the problem:</p>
<p><strong>Direct Token Revision</strong></p>
<ul>
<li><strong>&ldquo;Neural Text Degeneration with Iterative Target Text Revision&rdquo;</strong>  (<a href="https://aclanthology.org/2021.emnlp-main.90/">https://aclanthology.org/2021.emnlp-main.90/</a>). This paper explores a method where an LLM is used to both generate text and iteratively revise it, focusing on the problem of text degeneration (where outputs become less coherent).</li>
<li><strong>&ldquo;EDITNTS: An Neural Programmer-Interpreter for Image Editing&rdquo;</strong> (<a href="https://arxiv.org/abs/2108.02000">https://arxiv.org/abs/2108.02000</a>). While focused on image editing, the core concept involves a mechanism for revising previous steps. This type of &rsquo;editable memory&rsquo; could inspire LLM research.</li>
</ul>
<p><strong>Iterative Refinement and Search-based Approaches</strong></p>
<ul>
<li><strong>&ldquo;Creative Text Generation via Iterative Refinement with Multi-step Planning&rdquo;</strong> (<a href="https://aclanthology.org/2022.acl-long.370/">https://aclanthology.org/2022.acl-long.370/</a>). This explores generating multiple drafts and refining them, demonstrating how a revision-like approach can improve text creativity.</li>
<li><strong>Work on Nucleus Sampling (Top-p Sampling), Beam Search, and variations</strong>. These techniques implicitly allow for some &lsquo;backtracking&rsquo; if a previously less-favorable sequence turns out to yield very strong predictions.</li>
</ul>
<p><strong>Hybrid and Emerging Work</strong></p>
<ul>
<li><strong>Combining Reinforcement Learning with Revision</strong> There&rsquo;s potential to use reinforcement learning to train models to identify when and how revisions would be most beneficial.</li>
<li><strong>Attention-based Models and &ldquo;Scratchpads&rdquo;</strong> Research into giving LLMs a &lsquo;scratchpad&rsquo;, or editable workspace, could enable mechanisms closer to how we think and revise text.</li>
</ul>
<p><strong>Challenges and Notes</strong></p>
<ul>
<li>This is a relatively niche area compared to mainstream LLM development. Finding papers specifically targeting token revision might be tricky.</li>
<li>A lot of relevant work falls under areas like iterative refinement, controllable text generation, and techniques to combat LLM degeneration.</li>
</ul>
<p>Let me know if you&rsquo;d like me to dig for more specific papers or want to explore any of these directions in more detail!</p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://localhost:1313/" >
    &copy;  An eclectic mix of technical content! 2024 
  </a>
    <div>
<div class="ananke-socials">
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
